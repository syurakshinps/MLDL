{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"06ccad4deb764c988814539b421d754e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_737ad8ad91f945acad8455755726ab2b","IPY_MODEL_c708947c4d0a46539eb5d141829412ce","IPY_MODEL_de806482707a4e8592af0a3dbb323310"],"layout":"IPY_MODEL_7db3f9718c2544f3bb3d86a3e15246be"}},"737ad8ad91f945acad8455755726ab2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f039058401241129e0425b71577a37d","placeholder":"​","style":"IPY_MODEL_5be937b520ad4133b100601e3c21c801","value":"tokenizer_config.json: 100%"}},"c708947c4d0a46539eb5d141829412ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6afa3c2d7ba84031abb3c39a1b9fd72a","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4949958656f944fa960925481b29a466","value":48}},"de806482707a4e8592af0a3dbb323310":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_554f0e03bbc54dec83550702bdff4cae","placeholder":"​","style":"IPY_MODEL_f7cd399c51ba4702a8a4694f41cf51a7","value":" 48.0/48.0 [00:00&lt;00:00, 1.36kB/s]"}},"7db3f9718c2544f3bb3d86a3e15246be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f039058401241129e0425b71577a37d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5be937b520ad4133b100601e3c21c801":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6afa3c2d7ba84031abb3c39a1b9fd72a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4949958656f944fa960925481b29a466":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"554f0e03bbc54dec83550702bdff4cae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7cd399c51ba4702a8a4694f41cf51a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1abb2c473ad4463ba0ddcd7b0854747b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee900c9af5354ddc903175dd93caf417","IPY_MODEL_eb2c27e2ad8549089379433045b01741","IPY_MODEL_c8a499eff19741a288f31b0044a02f82"],"layout":"IPY_MODEL_15bcb753756245fe9b5e80bf779c8798"}},"ee900c9af5354ddc903175dd93caf417":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de457e581f5845da9641e2b59b2cfa57","placeholder":"​","style":"IPY_MODEL_0a2957ea3c80495e89b9f493ec2bc320","value":"config.json: 100%"}},"eb2c27e2ad8549089379433045b01741":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e03bb92daa344978ff7b34380a7a040","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d42d7d1295e44dae90285290bb3890ec","value":570}},"c8a499eff19741a288f31b0044a02f82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_105fd4da09414af7916801944b66c342","placeholder":"​","style":"IPY_MODEL_dc559f9ad793488a9ab918be1dedfac4","value":" 570/570 [00:00&lt;00:00, 7.73kB/s]"}},"15bcb753756245fe9b5e80bf779c8798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de457e581f5845da9641e2b59b2cfa57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2957ea3c80495e89b9f493ec2bc320":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e03bb92daa344978ff7b34380a7a040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d42d7d1295e44dae90285290bb3890ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"105fd4da09414af7916801944b66c342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc559f9ad793488a9ab918be1dedfac4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a13cc509de6426e9acd342b00a1f7da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d769c2fe99e49709ee1a0c1d97153ba","IPY_MODEL_a04f040ace0b4b04b28be5d545700bfd","IPY_MODEL_ab1962033bfe4f908c69ff2cf647b6fd"],"layout":"IPY_MODEL_8b215a42bc0545dbb3d81e1060878c46"}},"4d769c2fe99e49709ee1a0c1d97153ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91d63778cb204560b2f9e430305df3e8","placeholder":"​","style":"IPY_MODEL_01e40dce846b49a3a0cddd99d2b6e59a","value":"vocab.txt: 100%"}},"a04f040ace0b4b04b28be5d545700bfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_134ccb4cf2094df59efae8a6989f433e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adac60f55a7e45ffbcaa3ce4420b8146","value":231508}},"ab1962033bfe4f908c69ff2cf647b6fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01cfa89778ed4c759a8511ee5446c7e7","placeholder":"​","style":"IPY_MODEL_089f81585ef843de83b51faec2da6203","value":" 232k/232k [00:00&lt;00:00, 3.70MB/s]"}},"8b215a42bc0545dbb3d81e1060878c46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91d63778cb204560b2f9e430305df3e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e40dce846b49a3a0cddd99d2b6e59a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"134ccb4cf2094df59efae8a6989f433e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adac60f55a7e45ffbcaa3ce4420b8146":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01cfa89778ed4c759a8511ee5446c7e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"089f81585ef843de83b51faec2da6203":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34d28545c8584a1c8f4399ea015e6dae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53cdd5e59fb34de78cc7f467269b5e5d","IPY_MODEL_475f831c63b1482d9cb09c5ee28ebd70","IPY_MODEL_d4dd7ae2a5884673b3c6ff1e98e8d972"],"layout":"IPY_MODEL_2362a7d911d94d2fa7280c7fc790e464"}},"53cdd5e59fb34de78cc7f467269b5e5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b821f8e868e4a02b0cbca5791ee587c","placeholder":"​","style":"IPY_MODEL_f41f752c0cc74209821ed4f5b6f7e937","value":"tokenizer.json: 100%"}},"475f831c63b1482d9cb09c5ee28ebd70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f10bfa9b5b2419a95002a896bc9924c","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_928cafc9ea534955a3b46075d6db1166","value":466062}},"d4dd7ae2a5884673b3c6ff1e98e8d972":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca4f8c172bca45a5ac221d17ae9e6ae3","placeholder":"​","style":"IPY_MODEL_2587f80effc74a75a7032caef7480b76","value":" 466k/466k [00:00&lt;00:00, 11.8MB/s]"}},"2362a7d911d94d2fa7280c7fc790e464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b821f8e868e4a02b0cbca5791ee587c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f41f752c0cc74209821ed4f5b6f7e937":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f10bfa9b5b2419a95002a896bc9924c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"928cafc9ea534955a3b46075d6db1166":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca4f8c172bca45a5ac221d17ae9e6ae3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2587f80effc74a75a7032caef7480b76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8029417,"sourceType":"datasetVersion","datasetId":4732547}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\" width=\"400\"></p>\n\n# Глубокое обучение. Часть 2\n# Домашнее задание по теме \"Механизм внимания\"","metadata":{"id":"Ji8KtYOVGs8_"}},{"cell_type":"markdown","source":"Это домашнее задание проходит в формате peer-review. Это означает, что его будут проверять ваши однокурсники. Поэтому пишите разборчивый код, добавляйте комментарии и пишите выводы после проделанной работы.\n\nВ этом задании вы будете решать задачу классификации математических задач по темам (многоклассовая классификация) с помощью Transformer.\n\nВ качестве датасета возьмем датасет математических задач по разным темам. Нам необходим следующий файл:\n\n[Файл с классами](https://docs.google.com/spreadsheets/d/1IMRxByfg7gjoZ5i7rxvuNDvSrbdOJOc-/edit?usp=drive_link&ouid=104379615679964018037&rtpof=true&sd=true)","metadata":{"id":"UAr-M8_1GJ6W"}},{"cell_type":"code","source":"!ls -la /kaggle/input/no-problems/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -la /kaggle/working/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Задайте путь к вашему файлу\nfilepath = \"/kaggle/input/no-problems/data_problems.csv\"\n\n# Читаем данные из файла\ndata = pd.read_csv(filepath)\n\n# Просмотрим первые несколько строк данных\nprint(data.iloc[:0].head())\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"woqEwmWyzT2y","outputId":"7d8b1bb3-a268-44df-baee-d99cff32444e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Получаем первый столбец по индексу\nfirst_column = data.iloc[:, 2]\n\n# Находим уникальные значения\nunique_values = first_column.unique()\n\n# Подсчитываем количество уникальных значений\nnum_unique_values = len(unique_values)\n\nprint(f\"Количество уникальных значений в первом столбце: {num_unique_values}\")\nprint(f\"они сами: {unique_values}\")\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Akz_EoLX0qmC","outputId":"1b9c05cc-99ee-459d-f2e3-7672db0a7240","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Hint:** не перезаписывайте модели, которые вы получите на каждом из этапов этого дз. Они ещё понадобятся.","metadata":{"id":"1fybMcmV0YRA"}},{"cell_type":"markdown","source":"### Задание 1 (2 балла)\n\nНапишите кастомный класс для модели трансформера для задачи классификации, использующей в качествке backbone какую-то из моделей huggingface.\n\nТ.е. конструктор класса должен принимать на вход название модели и подгружать её из huggingface, а затем использовать в качестве backbone (достаточно возможности использовать в качестве backbone те модели, которые упомянуты в последующих пунктах)","metadata":{"id":"t395freCxpOE"}},{"cell_type":"code","source":"!pip install transformers","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qy-vTwYTanTP","outputId":"b2c953cf-952b-4608-ca8c-9f9157edd297","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel\nfrom typing import Union, Dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TransformerClassificationModel(nn.Module):\n    def __init__(self, base_transformer_model: Union[str, nn.Module], num_labels: int):\n        \"\"\"\n        Инициализация модели классификации на основе трансформера.\n        \n        Параметры:\n        base_transformer_model (Union[str, nn.Module]): Название предобученной модели трансформера из huggingface\n                                                        или экземпляр модели nn.Module.\n        num_labels (int): Количество классов для классификации.\n        \"\"\"\n        super(TransformerClassificationModel, self).__init__()\n        if isinstance(base_transformer_model, str):\n            self.backbone = AutoModel.from_pretrained(base_transformer_model)\n        else:\n            self.backbone = base_transformer_model\n        \n        # Добавляем дополнительные слои для классификации.\n        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Прямой проход модели.\n        \n        Параметры:\n        input_ids (torch.Tensor): Тензор идентификаторов токенов.\n        attention_mask (torch.Tensor, optional): Тензор масок внимания.\n        token_type_ids (torch.Tensor, optional): Тензор типов токенов.\n\n        Возвращает:\n        Dict[str, torch.Tensor]: Словарь с логитами предсказаний классов.\n        \"\"\"\n        # Пропагация входных данных через backbone.\n        outputs = self.backbone(input_ids=input_ids, \n                                attention_mask=attention_mask, \n                                token_type_ids=token_type_ids)\n        \n        # Используем [CLS] токен для классификации.\n        cls_token_state = outputs.last_hidden_state[:, 0, :]\n        \n        # Пропагация через классификационный слой.\n        logits = self.classifier(cls_token_state)\n\n        return {\"logits\": logits}\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 2 (1 балл)\n\nНапишите функцию заморозки backbone у модели (если необходимо, возвращайте из функции модель)","metadata":{"id":"Vd3kxX6hy0d4"}},{"cell_type":"code","source":"def freeze_backbone_function(model: TransformerClassificationModel):\n    # Перебираем все параметры в backbone модели\n    for param in model.backbone.parameters():\n        # Выключаем вычисление градиентов\n        param.requires_grad = False\n\n    # Возвращать модель необязательно, так как изменения произведены \"на месте\"\n    return model","metadata":{"id":"U8IuDosbzKe8","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 3 (2 балла)\n\nНапишите функцию, которая будет использована для тренировки (дообучения) трансформера (TransformerClassificationModel). Функция должна поддерживать обучение с замороженным и размороженным backbone.","metadata":{"id":"kybkw6MSzd-K"}},{"cell_type":"code","source":"import copy\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom transformers import get_linear_schedule_with_warmup\n\ndef train_transformer(model, data_loader, freeze_backbone=True, epochs=3, learning_rate=5e-5, num_training_steps=None):\n    # Создаем полную копию модели для ее дообучения\n    finetuned_model = copy.deepcopy(model)\n\n    # Замораживаем или размораживаем backbone\n    for param in finetuned_model.backbone.parameters():\n        param.requires_grad = not freeze_backbone\n\n    # Создаем оптимизатор, оптимизируя только параметры, требующие градиенты\n    optimizer = AdamW(filter(lambda p: p.requires_grad, finetuned_model.parameters()), lr=learning_rate)\n\n    # Предполагаем использование функции потерь CrossEntropyLoss для классификации\n    criterion = torch.nn.CrossEntropyLoss()\n\n    # Если определено количество шагов обучения, создаем планировщик для управления скоростью обучения\n    scheduler = None\n    if num_training_steps is not None:\n        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n\n    finetuned_model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for batch in data_loader:\n            # Предполагается, что DataLoader возвращает словарь с ключами 'input_ids', 'attention_mask', 'labels'\n            inputs = {k: v.to(finetuned_model.device) for k, v in batch.items() if k != 'labels'}\n            labels = batch['labels'].to(finetuned_model.device)\n\n            outputs = finetuned_model(**inputs)\n            loss = criterion(outputs['logits'], labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            if scheduler:\n                scheduler.step()\n\n            total_loss += loss.item()\n\n        print(f\"Epoch {epoch + 1}: Loss = {total_loss / len(data_loader)}\")\n\n    return finetuned_model\n","metadata":{"id":"EDhrD0BHzxi4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 4 (1 балл)\n\nПроверьте вашу функцию из предыдущего пункта, дообучив двумя способами\n*cointegrated/rubert-tiny2* из huggingface.","metadata":{"id":"eUqhI4mV_RTI"}},{"cell_type":"code","source":"from transformers import AutoModel, AutoConfig\nimport torch.nn as nn\n\nclass RubertTinyClassifier(nn.Module):\n    def __init__(self, pretrained_model_name, num_labels):\n        super(RubertTinyClassifier, self).__init__()\n        self.backbone = AutoModel.from_pretrained(pretrained_model_name)\n        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.to(self.device)\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n        pooler_output = outputs.pooler_output\n        logits = self.classifier(pooler_output)\n        return {'logits': logits}\n\n","metadata":{"id":"nuxOCBQHAKZC","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nimport torch\n","metadata":{"id":"yCu5_6sY27df","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Шаг 1: Загрузка данных\nfile_path = '/kaggle/input/no-problems/data_problems.csv'\ndf = pd.read_csv(file_path)\n\n# Шаг 2: Преобразование категорий в числовой формат\nunique_labels = df['Тема'].unique()\nlabel_to_id = {label: id for id, label in enumerate(unique_labels)}\nid_to_label = {id: label for label, id in label_to_id.items()}\n\ndf['label_id'] = df['Тема'].map(label_to_id)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Шаг 3: Создание класса Dataset\nclass MathProblemsDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=512):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.text = dataframe['Задача']\n        self.labels = dataframe['label_id']\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, idx):\n        text = str(self.text[idx])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=False,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        input_ids = inputs['input_ids'].flatten()\n        attention_mask = inputs['attention_mask'].flatten()\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n        }\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Шаг 4: Токенизация\n# Замените 'pretrained_model_name' на название модели, которую вы планируете использовать\npretrained_model_name = 'cointegrated/rubert-tiny2'\ntokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n\n# Создание экземпляра Dataset\ndataset = MathProblemsDataset(df, tokenizer)\n\n# Создание DataLoader\nloader = DataLoader(dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_LABELS = 11\n# Инициализация и дообучение с замороженным backbone\nrubert_tiny_transformer_model = RubertTinyClassifier(pretrained_model_name=\"cointegrated/rubert-tiny2\", num_labels=NUM_LABELS)\nrubert_tiny_finetuned_with_freezed_backbone = train_transformer(rubert_tiny_transformer_model, loader, freeze_backbone=True)\n\n# Инициализация и полное дообучение\nrubert_tiny_transformer_model = RubertTinyClassifier(pretrained_model_name=\"cointegrated/rubert-tiny2\", num_labels=NUM_LABELS)\nrubert_tiny_full_finetuned = train_transformer(rubert_tiny_transformer_model, loader, freeze_backbone=False)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"gmIy9EPQyQFW","outputId":"3a399a92-254f-458f-e2a2-80ace4ac4d47","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохранение модели после обучения с замороженным backbone\nmodel_path = \"/kaggle/working/rubert_tiny_finetuned_with_freezed_backbone.pth\"\ntorch.save(rubert_tiny_finetuned_with_freezed_backbone.state_dict(), model_path)\n\n# Сохранение модели после полного обучения\nmodel_path = \"/kaggle/working/rubert_tiny_full_finetuned.pth\"\ntorch.save(rubert_tiny_full_finetuned.state_dict(), model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# перед обучением 2й модели очистим видеко память\nimport torch\nimport gc\n\ndel rubert_tiny_transformer_model\ndel rubert_tiny_finetuned_with_freezed_backbone \ndel rubert_tiny_full_finetuned\ngc.collect()  # Сборка мусора в Python (освобождение памяти)\ntorch.cuda.empty_cache()  # Освобождение неиспользуемой памяти на GPU","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 5 (1 балл)\n\nОбучите *tbs17/MathBert* (с замороженным backbone и без заморозки), проанализируйте результаты. Сравните скоры с первым заданием. Получилось лучше или нет? Почему?","metadata":{"id":"zRi7tkoOAjon"}},{"cell_type":"code","source":"from transformers import AutoModel, AutoConfig\nimport torch.nn as nn\nimport torch\n\n","metadata":{"id":"XKtd3YgNA14E","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Загрузка токенизатора для модели tbs17/MathBert\ntokenizer = AutoTokenizer.from_pretrained(\"tbs17/MathBert\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from torch.utils.data import DataLoader\n\n# Замените 'pretrained_model_name' на название новой модели, которую вы планируете использовать\npretrained_model_name = 'tbs17/MathBert'\ntokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n\n# Создание экземпляра Dataset\ndataset = MathProblemsDataset(df, tokenizer)\n\n# Создание DataLoader\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass MathBertClassifier(nn.Module):\n    def __init__(self, pretrained_model_name, num_labels):\n        super(MathBertClassifier, self).__init__()\n        self.backbone = AutoModel.from_pretrained(pretrained_model_name)\n        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.to(self.device)\n\n    def forward(self, input_ids, attention_mask=None):\n        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n        pooler_output = outputs.pooler_output\n        logits = self.classifier(pooler_output)\n        return {'logits': logits}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_LABELS = 11  # Убедитесь, что это количество уникальных классов в вашем датасете\n\n# Инициализация и дообучение с замороженным backbone\nmath_bert_model_frozen = MathBertClassifier(pretrained_model_name=\"tbs17/MathBert\", num_labels=NUM_LABELS)\nmath_bert_finetuned_frozen = train_transformer(math_bert_model_frozen, loader, freeze_backbone=True)\n\n# Инициализация и полное дообучение\nmath_bert_model_unfrozen = MathBertClassifier(pretrained_model_name=\"tbs17/MathBert\", num_labels=NUM_LABELS)\nmath_bert_finetuned_unfrozen = train_transformer(math_bert_model_unfrozen, loader, freeze_backbone=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 6 (1 балл)\n\nНапишите функцию для отрисовки карт внимания первого слоя для моделей из задания","metadata":{"id":"EuU6Di26017B"}},{"cell_type":"code","source":"def draw_first_layer_attention_maps(attention_head_ids: List, text: str, model: TransformerClassificationModel):\n    pass","metadata":{"id":"guzGxfcV1Cba"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 7 (1 балл)\n\nПроведите инференс для всех моделей **ДО ДООБУЧЕНИЯ** на 2-3 текстах из датасета. Посмотрите на головы Attention первого слоя в каждой модели на выбранных текстах (отрисуйте их отдельно).\n\nПопробуйте их проинтерпретировать. Какие связи улавливают карты внимания? (если в модели много голов Attention, то проинтерпретируйте наиболее интересные)","metadata":{"id":"Iu0adKw4BLtF"}},{"cell_type":"code","source":"### YOUR CODE IS HERE","metadata":{"id":"U2gEF3vkB6eR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 8 (1 балл)\n\nСделайте то же самое для дообученных моделей. Изменились ли карты внимания и связи, которые они улавливают? Почему?","metadata":{"id":"pBNVrOpCCLqk"}},{"cell_type":"code","source":"### YOUR CODE IS HERE","metadata":{"id":"F5229WBICWEr"},"execution_count":null,"outputs":[]}]}