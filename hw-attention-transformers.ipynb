{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"06ccad4deb764c988814539b421d754e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_737ad8ad91f945acad8455755726ab2b","IPY_MODEL_c708947c4d0a46539eb5d141829412ce","IPY_MODEL_de806482707a4e8592af0a3dbb323310"],"layout":"IPY_MODEL_7db3f9718c2544f3bb3d86a3e15246be"}},"737ad8ad91f945acad8455755726ab2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f039058401241129e0425b71577a37d","placeholder":"​","style":"IPY_MODEL_5be937b520ad4133b100601e3c21c801","value":"tokenizer_config.json: 100%"}},"c708947c4d0a46539eb5d141829412ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6afa3c2d7ba84031abb3c39a1b9fd72a","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4949958656f944fa960925481b29a466","value":48}},"de806482707a4e8592af0a3dbb323310":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_554f0e03bbc54dec83550702bdff4cae","placeholder":"​","style":"IPY_MODEL_f7cd399c51ba4702a8a4694f41cf51a7","value":" 48.0/48.0 [00:00&lt;00:00, 1.36kB/s]"}},"7db3f9718c2544f3bb3d86a3e15246be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f039058401241129e0425b71577a37d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5be937b520ad4133b100601e3c21c801":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6afa3c2d7ba84031abb3c39a1b9fd72a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4949958656f944fa960925481b29a466":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"554f0e03bbc54dec83550702bdff4cae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7cd399c51ba4702a8a4694f41cf51a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1abb2c473ad4463ba0ddcd7b0854747b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee900c9af5354ddc903175dd93caf417","IPY_MODEL_eb2c27e2ad8549089379433045b01741","IPY_MODEL_c8a499eff19741a288f31b0044a02f82"],"layout":"IPY_MODEL_15bcb753756245fe9b5e80bf779c8798"}},"ee900c9af5354ddc903175dd93caf417":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de457e581f5845da9641e2b59b2cfa57","placeholder":"​","style":"IPY_MODEL_0a2957ea3c80495e89b9f493ec2bc320","value":"config.json: 100%"}},"eb2c27e2ad8549089379433045b01741":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e03bb92daa344978ff7b34380a7a040","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d42d7d1295e44dae90285290bb3890ec","value":570}},"c8a499eff19741a288f31b0044a02f82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_105fd4da09414af7916801944b66c342","placeholder":"​","style":"IPY_MODEL_dc559f9ad793488a9ab918be1dedfac4","value":" 570/570 [00:00&lt;00:00, 7.73kB/s]"}},"15bcb753756245fe9b5e80bf779c8798":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de457e581f5845da9641e2b59b2cfa57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a2957ea3c80495e89b9f493ec2bc320":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e03bb92daa344978ff7b34380a7a040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d42d7d1295e44dae90285290bb3890ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"105fd4da09414af7916801944b66c342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc559f9ad793488a9ab918be1dedfac4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a13cc509de6426e9acd342b00a1f7da":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d769c2fe99e49709ee1a0c1d97153ba","IPY_MODEL_a04f040ace0b4b04b28be5d545700bfd","IPY_MODEL_ab1962033bfe4f908c69ff2cf647b6fd"],"layout":"IPY_MODEL_8b215a42bc0545dbb3d81e1060878c46"}},"4d769c2fe99e49709ee1a0c1d97153ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_91d63778cb204560b2f9e430305df3e8","placeholder":"​","style":"IPY_MODEL_01e40dce846b49a3a0cddd99d2b6e59a","value":"vocab.txt: 100%"}},"a04f040ace0b4b04b28be5d545700bfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_134ccb4cf2094df59efae8a6989f433e","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adac60f55a7e45ffbcaa3ce4420b8146","value":231508}},"ab1962033bfe4f908c69ff2cf647b6fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01cfa89778ed4c759a8511ee5446c7e7","placeholder":"​","style":"IPY_MODEL_089f81585ef843de83b51faec2da6203","value":" 232k/232k [00:00&lt;00:00, 3.70MB/s]"}},"8b215a42bc0545dbb3d81e1060878c46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91d63778cb204560b2f9e430305df3e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01e40dce846b49a3a0cddd99d2b6e59a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"134ccb4cf2094df59efae8a6989f433e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adac60f55a7e45ffbcaa3ce4420b8146":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"01cfa89778ed4c759a8511ee5446c7e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"089f81585ef843de83b51faec2da6203":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34d28545c8584a1c8f4399ea015e6dae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53cdd5e59fb34de78cc7f467269b5e5d","IPY_MODEL_475f831c63b1482d9cb09c5ee28ebd70","IPY_MODEL_d4dd7ae2a5884673b3c6ff1e98e8d972"],"layout":"IPY_MODEL_2362a7d911d94d2fa7280c7fc790e464"}},"53cdd5e59fb34de78cc7f467269b5e5d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b821f8e868e4a02b0cbca5791ee587c","placeholder":"​","style":"IPY_MODEL_f41f752c0cc74209821ed4f5b6f7e937","value":"tokenizer.json: 100%"}},"475f831c63b1482d9cb09c5ee28ebd70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f10bfa9b5b2419a95002a896bc9924c","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_928cafc9ea534955a3b46075d6db1166","value":466062}},"d4dd7ae2a5884673b3c6ff1e98e8d972":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca4f8c172bca45a5ac221d17ae9e6ae3","placeholder":"​","style":"IPY_MODEL_2587f80effc74a75a7032caef7480b76","value":" 466k/466k [00:00&lt;00:00, 11.8MB/s]"}},"2362a7d911d94d2fa7280c7fc790e464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b821f8e868e4a02b0cbca5791ee587c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f41f752c0cc74209821ed4f5b6f7e937":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f10bfa9b5b2419a95002a896bc9924c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"928cafc9ea534955a3b46075d6db1166":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ca4f8c172bca45a5ac221d17ae9e6ae3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2587f80effc74a75a7032caef7480b76":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8029417,"sourceType":"datasetVersion","datasetId":4732547}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\" width=\"400\"></p>\n\n# Глубокое обучение. Часть 2\n# Домашнее задание по теме \"Механизм внимания\"","metadata":{"id":"Ji8KtYOVGs8_"}},{"cell_type":"markdown","source":"Это домашнее задание проходит в формате peer-review. Это означает, что его будут проверять ваши однокурсники. Поэтому пишите разборчивый код, добавляйте комментарии и пишите выводы после проделанной работы.\n\nВ этом задании вы будете решать задачу классификации математических задач по темам (многоклассовая классификация) с помощью Transformer.\n\nВ качестве датасета возьмем датасет математических задач по разным темам. Нам необходим следующий файл:\n\n[Файл с классами](https://docs.google.com/spreadsheets/d/1IMRxByfg7gjoZ5i7rxvuNDvSrbdOJOc-/edit?usp=drive_link&ouid=104379615679964018037&rtpof=true&sd=true)","metadata":{"id":"UAr-M8_1GJ6W"}},{"cell_type":"code","source":"!ls -la /kaggle/input/no-problems/","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:53.649474Z","iopub.execute_input":"2024-04-13T08:07:53.649795Z","iopub.status.idle":"2024-04-13T08:07:54.002863Z","shell.execute_reply.started":"2024-04-13T08:07:53.649768Z","shell.execute_reply":"2024-04-13T08:07:54.000883Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"total 2832\ndrwxr-xr-x 2 nobody nogroup       0 Apr 13 08:07 .\ndrwxr-xr-x 3 root   root       4096 Apr 13 08:07 ..\n-rw-r--r-- 1 nobody nogroup 2892351 Apr 13 08:07 data_problems.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!ls -la /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:07:58.356539Z","iopub.execute_input":"2024-04-13T08:07:58.356885Z","iopub.status.idle":"2024-04-13T08:07:58.674193Z","shell.execute_reply.started":"2024-04-13T08:07:58.356857Z","shell.execute_reply":"2024-04-13T08:07:58.673315Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"total 12\ndrwxr-xr-x 3 root root 4096 Apr 13 08:07 .\ndrwxr-xr-x 5 root root 4096 Apr 13 08:07 ..\ndrwxr-xr-x 2 root root 4096 Apr 13 08:07 .virtual_documents\n","output_type":"stream"}]},{"cell_type":"markdown","source":"загрузил эксельку в csv на каггл","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nfilepath = \"/kaggle/input/no-problems/data_problems.csv\"\n\ndata = pd.read_csv(filepath)\n\nprint(data.head())\n","metadata":{"id":"woqEwmWyzT2y","outputId":"7d8b1bb3-a268-44df-baee-d99cff32444e","execution":{"iopub.status.busy":"2024-04-13T08:08:54.000247Z","iopub.execute_input":"2024-04-13T08:08:54.001241Z","iopub.status.idle":"2024-04-13T08:08:55.225533Z","shell.execute_reply.started":"2024-04-13T08:08:54.001205Z","shell.execute_reply":"2024-04-13T08:08:55.224191Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"   Unnamed: 0                                             Задача   Тема\n0           0  Между девятью планетами Солнечной системы введ...  Графы\n1           1  В стране Цифра есть 9 городов с названиями 1, ...  Графы\n2           2  В государстве 100 городов, и из каждого из них...  Графы\n3           3  В классе 30 человек. Может ли быть так, что 9 ...  Графы\n4           4  В городе Маленьком 15 телефонов. Можно ли их с...  Графы\n","output_type":"stream"}]},{"cell_type":"code","source":"# Получаем данные в столбце Тема по индексу\nfirst_column = data.iloc[:, 2]\n\n# Находим уникальные значения\nunique_values = first_column.unique()\n\n# Подсчитываем количество уникальных значений\nnum_unique_values = len(unique_values)\n\nprint(f\"Количество уникальных значений в столбце Тема: {num_unique_values}\")\nprint(f\"они сами: {unique_values}\")\n","metadata":{"id":"Akz_EoLX0qmC","outputId":"1b9c05cc-99ee-459d-f2e3-7672db0a7240","execution":{"iopub.status.busy":"2024-04-13T08:09:13.329328Z","iopub.execute_input":"2024-04-13T08:09:13.329859Z","iopub.status.idle":"2024-04-13T08:09:13.341076Z","shell.execute_reply.started":"2024-04-13T08:09:13.329799Z","shell.execute_reply":"2024-04-13T08:09:13.340191Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Количество уникальных значений в столбце Тема: 7\nони сами: ['Графы' 'Геометрия' 'Многочлен' 'Комбинаторика' 'Теория чисел'\n 'Инвариант' 'Дирихле']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Hint:** не перезаписывайте модели, которые вы получите на каждом из этапов этого дз. Они ещё понадобятся.","metadata":{"id":"1fybMcmV0YRA"}},{"cell_type":"markdown","source":"### Задание 1 (2 балла)\n\nНапишите кастомный класс для модели трансформера для задачи классификации, использующей в качествке backbone какую-то из моделей huggingface.\n\nТ.е. конструктор класса должен принимать на вход название модели и подгружать её из huggingface, а затем использовать в качестве backbone (достаточно возможности использовать в качестве backbone те модели, которые упомянуты в последующих пунктах)","metadata":{"id":"t395freCxpOE"}},{"cell_type":"code","source":"!pip install transformers","metadata":{"id":"Qy-vTwYTanTP","outputId":"b2c953cf-952b-4608-ca8c-9f9157edd297","execution":{"iopub.status.busy":"2024-04-13T08:09:23.434819Z","iopub.execute_input":"2024-04-13T08:09:23.435169Z","iopub.status.idle":"2024-04-13T08:09:35.372500Z","shell.execute_reply.started":"2024-04-13T08:09:23.435141Z","shell.execute_reply":"2024-04-13T08:09:35.371329Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel\nfrom typing import Union, Dict\n\nprint(\"ok\")","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:10:06.550376Z","iopub.execute_input":"2024-04-13T08:10:06.550730Z","iopub.status.idle":"2024-04-13T08:10:12.582658Z","shell.execute_reply.started":"2024-04-13T08:10:06.550699Z","shell.execute_reply":"2024-04-13T08:10:12.581322Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"# как на странно именно этот класс потом не использую :-)\nclass TransformerClassificationModel(nn.Module):\n    def __init__(self, base_transformer_model: Union[str, nn.Module], num_labels: int, output_attentions=False):\n        \"\"\"\n        Инициализация модели классификации на основе трансформера.\n        \n        Параметры:\n        base_transformer_model (Union[str, nn.Module]): Название предобученной модели трансформера из huggingface\n                                                        или экземпляр модели nn.Module.\n        num_labels (int): Количество классов для классификации.\n        output_attentions (bool): Если True, модель будет возвращать слои внимания.\n        \"\"\"\n        super(TransformerClassificationModel, self).__init__()\n        self.output_attentions = output_attentions\n        if isinstance(base_transformer_model, str):\n            self.backbone = AutoModel.from_pretrained(base_transformer_model, output_attentions=output_attentions)\n        else:\n            self.backbone = base_transformer_model\n        \n        # Добавляем дополнительные слои для классификации.\n        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n        \n        # Для сохранения истории потерь и точности\n        self.training_losses = []\n        self.training_accuracies = []\n        self.validation_losses = []\n        self.validation_accuracies = []\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None) -> Dict[str, torch.Tensor]:\n        \"\"\"\n        Прямой проход модели.\n        \n        Параметры:\n        input_ids (torch.Tensor): Тензор идентификаторов токенов.\n        attention_mask (torch.Tensor, optional): Тензор масок внимания.\n        token_type_ids (torch.Tensor, optional): Тензор типов токенов.\n\n        Возвращает:\n        Dict[str, torch.Tensor]: Словарь с логитами предсказаний классов и, при наличии, слои внимания.\n        \"\"\"\n        # Пропагация входных данных через backbone.\n        outputs = self.backbone(input_ids=input_ids, \n                                attention_mask=attention_mask, \n                                token_type_ids=token_type_ids,\n                                output_attentions=self.output_attentions)\n        \n        # Используем [CLS] токен для классификации.\n        cls_token_state = outputs.last_hidden_state[:, 0, :]\n        \n        # Пропагация через классификационный слой.\n        logits = self.classifier(cls_token_state)\n\n        response = {\"logits\": logits}\n        if self.output_attentions:\n            response[\"attentions\"] = outputs.attentions\n\n        return response\n\n    def add_metrics(self, train_loss, train_accuracy, val_loss=None, val_accuracy=None):\n        self.training_losses.append(train_loss)\n        self.training_accuracies.append(train_accuracy)\n        if val_loss is not None and val_accuracy is not None:\n            self.validation_losses.append(val_loss)\n            self.validation_accuracies.append(val_accuracy)\n\n    def get_metrics(self):\n        return {\n            \"training_losses\": self.training_losses,\n            \"training_accuracies\": self.training_accuracies,\n            \"validation_losses\": self.validation_losses,\n            \"validation_accuracies\": self.validation_accuracies\n        }\n    \nprint(\"ok\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-13T08:11:03.199779Z","iopub.execute_input":"2024-04-13T08:11:03.200370Z","iopub.status.idle":"2024-04-13T08:11:03.214669Z","shell.execute_reply.started":"2024-04-13T08:11:03.200341Z","shell.execute_reply":"2024-04-13T08:11:03.213718Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Задание 2 (1 балл)\n\nНапишите функцию заморозки backbone у модели (если необходимо, возвращайте из функции модель)","metadata":{"id":"Vd3kxX6hy0d4"}},{"cell_type":"code","source":"def freeze_backbone_function(model: TransformerClassificationModel):\n    # Перебираем все параметры в backbone модели\n    for param in model.backbone.parameters():\n        # Выключаем вычисление градиентов\n        param.requires_grad = False\n\n    # Возвращать модель необязательно, так как изменения произведены \"на месте\"\n    return model\n\nprint(\"ok\")","metadata":{"id":"U8IuDosbzKe8","execution":{"iopub.status.busy":"2024-04-13T08:11:26.622112Z","iopub.execute_input":"2024-04-13T08:11:26.622723Z","iopub.status.idle":"2024-04-13T08:11:26.627536Z","shell.execute_reply.started":"2024-04-13T08:11:26.622694Z","shell.execute_reply":"2024-04-13T08:11:26.626952Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Задание 3 (2 балла)\n\nНапишите функцию, которая будет использована для тренировки (дообучения) трансформера (TransformerClassificationModel). Функция должна поддерживать обучение с замороженным и размороженным backbone.","metadata":{"id":"kybkw6MSzd-K"}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nimport copy\n\ndef train_transformer(model, data_loader, freeze_backbone=True, epochs=3, learning_rate=5e-5, num_training_steps=None, val_loader=None):\n    # Предполагаем, что модель уже содержит методы add_metrics и get_metrics\n    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n    criterion = torch.nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        correct_predictions = 0\n        total_predictions = 0\n\n        for batch in data_loader:\n            inputs = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n            labels = batch['labels'].to(model.device)\n\n            outputs = model(**inputs)\n            loss = criterion(outputs['logits'], labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs['logits'], 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.size(0)\n\n        train_loss = total_loss / len(data_loader)\n        train_accuracy = correct_predictions / total_predictions\n\n        # Если есть валидационный DataLoader, вычисляем потери и точность для валидации\n        if val_loader:\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            with torch.no_grad():\n                for batch in val_loader:\n                    inputs = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n                    labels = batch['labels'].to(model.device)\n                    outputs = model(**inputs)\n                    loss = criterion(outputs['logits'], labels)\n                    val_loss += loss.item()\n                    _, predicted = torch.max(outputs['logits'], 1)\n                    val_correct += (predicted == labels).sum().item()\n                    val_total += labels.size(0)\n\n            val_loss /= len(val_loader)\n            val_accuracy = val_correct / val_total\n            model.add_metrics(train_loss, train_accuracy, val_loss, val_accuracy)\n        else:\n            model.add_metrics(train_loss, train_accuracy)\n\n    return model\n\nprint(\"ok\")\n","metadata":{"id":"EDhrD0BHzxi4","execution":{"iopub.status.busy":"2024-04-13T08:13:37.884922Z","iopub.execute_input":"2024-04-13T08:13:37.885259Z","iopub.status.idle":"2024-04-13T08:13:37.905203Z","shell.execute_reply.started":"2024-04-13T08:13:37.885231Z","shell.execute_reply":"2024-04-13T08:13:37.903935Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Задание 4 (1 балл)\n\nПроверьте вашу функцию из предыдущего пункта, дообучив двумя способами\n*cointegrated/rubert-tiny2* из huggingface.","metadata":{"id":"eUqhI4mV_RTI"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel\n\nclass RubertTinyClassifier(nn.Module):\n    def __init__(self, pretrained_model_name, num_labels, output_attentions=False):\n        super(RubertTinyClassifier, self).__init__()\n        self.backbone = AutoModel.from_pretrained(pretrained_model_name, output_attentions=output_attentions)\n        self.classifier = nn.Linear(self.backbone.config.hidden_size, num_labels)\n        self.output_attentions = output_attentions  # Сохраняем параметр output_attentions\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.to(self.device)\n\n        # Инициализация списков для хранения метрик обучения и валидации\n        self.training_losses = []\n        self.training_accuracies = []\n        self.validation_losses = []\n        self.validation_accuracies = []\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n        # Выполняем прямой проход, запрашивая карты внимания при необходимости\n        outputs = self.backbone(input_ids=input_ids, \n                                attention_mask=attention_mask, \n                                token_type_ids=token_type_ids,\n                                output_attentions=self.output_attentions)\n        pooler_output = outputs.pooler_output\n        logits = self.classifier(pooler_output)\n        \n        response = {'logits': logits}\n        if self.output_attentions and 'attentions' in outputs:\n            response['attentions'] = outputs.attentions\n        \n        return response\n\n    def add_metrics(self, train_loss, train_accuracy, val_loss=None, val_accuracy=None):\n        self.training_losses.append(train_loss)\n        self.training_accuracies.append(train_accuracy)\n        if val_loss is not None and val_accuracy is not None:\n            self.validation_losses.append(val_loss)\n            self.validation_accuracies.append(val_accuracy)\n\n    def get_metrics(self):\n        return {\n            \"training_losses\": self.training_losses,\n            \"training_accuracies\": self.training_accuracies,\n            \"validation_losses\": self.validation_losses,\n            \"validation_accuracies\": self.validation_accuracies\n        }\n\n\nprint(\"ok\")\n\n","metadata":{"id":"nuxOCBQHAKZC","execution":{"iopub.status.busy":"2024-04-13T08:15:35.574679Z","iopub.execute_input":"2024-04-13T08:15:35.575103Z","iopub.status.idle":"2024-04-13T08:15:35.586425Z","shell.execute_reply.started":"2024-04-13T08:15:35.575069Z","shell.execute_reply":"2024-04-13T08:15:35.585494Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"ok\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\nimport torch\n","metadata":{"id":"yCu5_6sY27df","execution":{"iopub.status.busy":"2024-04-13T08:15:51.998760Z","iopub.execute_input":"2024-04-13T08:15:51.999152Z","iopub.status.idle":"2024-04-13T08:15:52.011354Z","shell.execute_reply.started":"2024-04-13T08:15:51.999124Z","shell.execute_reply":"2024-04-13T08:15:52.009650Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# создаем датасет(ы)\n# Шаг 1: Загрузка данных\nfile_path = '/kaggle/input/no-problems/data_problems.csv'\ndf = pd.read_csv(file_path)\n\n# Шаг 2: Преобразование категорий в числовой формат\nunique_labels = df['Тема'].unique()\nlabel_to_id = {label: id for id, label in enumerate(unique_labels)}\nid_to_label = {id: label for label, id in label_to_id.items()}\n\ndf['label_id'] = df['Тема'].map(label_to_id)\n\nprint(\"ok\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Шаг 3: Создание класса Dataset\nclass MathProblemsDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_len=512):\n        self.tokenizer = tokenizer\n        self.data = dataframe\n        self.text = dataframe['Задача']\n        self.labels = dataframe['label_id']\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, idx):\n        text = str(self.text[idx])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_token_type_ids=False,\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n\n        input_ids = inputs['input_ids'].flatten()\n        attention_mask = inputs['attention_mask'].flatten()\n\n        return {\n            'input_ids': input_ids,\n            'attention_mask': attention_mask,\n            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n        }\n\nprint(\"ok\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Шаг 4: Токенизация\n# pretrained_model_name = название модели, которую будем использовать\npretrained_model_name = 'cointegrated/rubert-tiny2'\ntokenizer = AutoTokenizer.from_pretrained(pretrained_model_name)\n\n# Создание экземпляра Dataset\ndataset = MathProblemsDataset(df, tokenizer)\n\n\n\nprint(\"ok\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\n# Определяем размеры для разделения\ntotal_count = len(dataset)\ntrain_count = int(0.7 * total_count)  # 70% данных на тренировку\nval_count = int(0.15 * total_count)   # 15% данных на валидацию\ntest_count = total_count - train_count - val_count  # Оставшиеся 15% данных на тест\n\n# Разделим dataset\ntrain_dataset, val_dataset, test_dataset = random_split(dataset, [train_count, val_count, test_count])\n\n# Проверим, что размеры наборов данных верны\nprint(f\"Total: {total_count}, Train: {len(train_dataset)}, Validation: {len(val_dataset)}, Test: {len(test_dataset)}\")\n\nprint(\"ok\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создание DataLoader для тренировочного набора\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# Создание DataLoader для валидационного набора\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Создание DataLoader для тестового набора\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nprint(\"ok\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# будет нужна функция\ndef evaluate(model, data_loader):\n    model.eval()  # Перевод модели в режим оценки\n    correct_predictions = 0\n    total_predictions = 0\n\n    with torch.no_grad():  # Отключение вычисления градиентов\n        for batch in data_loader:\n            inputs = {k: v.to(model.device) for k, v in batch.items() if k != 'labels'}\n            labels = batch['labels'].to(model.device)\n\n            outputs = model(**inputs)\n            _, predicted = torch.max(outputs['logits'], 1)\n\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.size(0)\n\n    accuracy = correct_predictions / total_predictions\n    return accuracy   \n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_LABELS = 7 # в самом начале подсмотрели, сколько там классов\n\n# Инициализация и дообучение с замороженным backbone\nrubert_tiny_transformer_model = RubertTinyClassifier(pretrained_model_name=\"cointegrated/rubert-tiny2\", num_labels=NUM_LABELS, output_attentions=True)\nrubert_tiny_finetuned_with_freezed_backbone = train_transformer(rubert_tiny_transformer_model, train_loader, freeze_backbone=True, val_loader=val_loader)\n\nmetrics_freezed = rubert_tiny_finetuned_with_freezed_backbone.get_metrics()\nprint(metrics_freezed['training_losses'])\nprint(metrics_freezed['training_accuracies'])\nif 'validation_losses' in metrics_freezed:\n    print(metrics_freezed['validation_losses'])\n    print(metrics_freezed['validation_accuracies'])\n    \ntest_accuracy = evaluate(rubert_tiny_finetuned_with_freezed_backbone, test_loader)\nprint(f\"Test Accuracy: {test_accuracy}\")\n\n# Инициализация и полное дообучение\nrubert_tiny_transformer_model = RubertTinyClassifier(pretrained_model_name=\"cointegrated/rubert-tiny2\", num_labels=NUM_LABELS, output_attentions=True)\nrubert_tiny_full_finetuned = train_transformer(rubert_tiny_transformer_model, train_loader, freeze_backbone=False, val_loader=val_loader)\n\nmetrics_unfreezed = rubert_tiny_full_finetuned.get_metrics()\nprint(metrics_unfreezed['training_losses'])\nprint(metrics_unfreezed['training_accuracies'])\nif 'validation_losses' in metrics_unfreezed:\n    print(metrics_unfreezed['validation_losses'])\n    print(metrics_unfreezed['validation_accuracies'])\n    \ntest_accuracy = evaluate(rubert_tiny_full_finetuned, test_loader)\nprint(f\"Test Accuracy: {test_accuracy}\")\n\nprint(\"ok\")\n","metadata":{"id":"gmIy9EPQyQFW","outputId":"3a399a92-254f-458f-e2a2-80ace4ac4d47","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# нарисуем графики\nimport matplotlib.pyplot as plt\n\n# Функция для отрисовки графиков\ndef plot_metrics(train_losses, train_accuracies, val_losses, val_accuracies):\n    epochs = range(1, len(train_losses) + 1)\n\n    plt.figure(figsize=(12, 5))\n\n    # Построение графика потерь\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, train_losses, 'b-', label='Training Loss')\n    plt.plot(epochs, val_losses, 'r-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    # Построение графика точности\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, train_accuracies, 'b-', label='Training Accuracy')\n    plt.plot(epochs, val_accuracies, 'r-', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = metrics_freezed['training_losses']\ntrain_accuracies = metrics_freezed['training_accuracies']\nval_losses = metrics_freezed['validation_losses']\nval_accuracies = metrics_freezed['validation_accuracies']\nplot_metrics(train_losses, train_accuracies, val_losses, val_accuracies)\n\n\ntrain_losses = metrics_unfreezed['training_losses']\ntrain_accuracies = metrics_unfreezed['training_accuracies']\nval_losses = metrics_unfreezed['validation_losses']\nval_accuracies = metrics_unfreezed['validation_accuracies']\nplot_metrics(train_losses, train_accuracies, val_losses, val_accuracies)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Сохранение модели после обучения с замороженным backbone\nmodel_path = \"/kaggle/working/rubert_tiny_finetuned_with_freezed_backbone.pth\"\ntorch.save(rubert_tiny_finetuned_with_freezed_backbone.state_dict(), model_path)\n\n# Сохранение модели после полного обучения\nmodel_path = \"/kaggle/working/rubert_tiny_full_finetuned.pth\"\ntorch.save(rubert_tiny_full_finetuned.state_dict(), model_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom IPython.display import FileLink\n\n# Путь к файлу на вашем ноутбуке Kaggle\nfile_path = '/kaggle/working/rubert_tiny_finetuned_with_freezed_backbone.pth'\n\n# Проверяем, существует ли файл\nif os.path.isfile(file_path):\n    # Создаем ссылку для скачивания\n    download_link = FileLink(file_path, result_html_prefix=\"Click here to download: \")\n    display(download_link)\nelse:\n    print(\"Файл не найден\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Путь к файлу на вашем ноутбуке Kaggle\nfile_path = '/kaggle/working/rubert_tiny_full_finetuned.pth'\n\n# Проверяем, существует ли файл\nif os.path.isfile(file_path):\n    # Создаем ссылку для скачивания\n    download_link = FileLink(file_path, result_html_prefix=\"Click here to download: \")\n    display(download_link)\nelse:\n    print(\"Файл не найден\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 5 (1 балл)\n\nОбучите *tbs17/MathBert* (с замороженным backbone и без заморозки), проанализируйте результаты. Сравните скоры с первым заданием. Получилось лучше или нет? Почему?","metadata":{"id":"zRi7tkoOAjon"}},{"cell_type":"markdown","source":"### Задание 6 (1 балл)\n\nНапишите функцию для отрисовки карт внимания первого слоя для моделей из задания","metadata":{"id":"EuU6Di26017B"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport torch\nfrom transformers import AutoTokenizer\n\nimport matplotlib.pyplot as plt\n\ndef draw_first_layer_attention_maps(attention_head_ids, text, model, tokenizer):\n    # Подготовка входных данных\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    input_ids = inputs['input_ids'].to(model.device)  # Убедитесь, что тензоры перенесены на нужное устройство\n    attention_mask = inputs['attention_mask'].to(model.device)\n\n    # Установка модели в режим оценки\n    model.eval()\n\n    # Включаем вычисление внимания\n    with torch.no_grad():\n        # Получаем внимание\n        outputs = model(input_ids, attention_mask=attention_mask)\n        attentions = outputs['attentions']\n\n    # Выбор первого слоя внимания\n    first_layer_attention = attentions[0]  # (batch_size, num_heads, seq_length, seq_length)\n    num_heads = first_layer_attention.size(1)\n\n    # Получаем токены для подписей\n    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n\n    # Визуализация карт внимания для указанных голов\n    fig, axes = plt.subplots(1, len(attention_head_ids), figsize=(20, 10))\n\n    if len(attention_head_ids) == 1:\n        axes = [axes]  # Обеспечиваем итерируемость для одного элемента\n\n    for i, head_id in enumerate(attention_head_ids):\n        # Проверка на корректность номера головы\n        if head_id < 0 or head_id >= num_heads:\n            raise ValueError(f\"Head id {head_id} is out of valid range [0, {num_heads-1}]\")\n\n        # Перемещаем тензор на CPU перед конвертацией в NumPy\n        attention = first_layer_attention[0, head_id].cpu().numpy()\n\n        ax = axes[i]\n        cax = ax.matshow(attention, cmap='viridis')\n        fig.colorbar(cax, ax=ax)\n        ax.set_xticks(range(len(tokens)))\n        ax.set_yticks(range(len(tokens)))\n        ax.set_xticklabels(tokens, rotation=90)\n        ax.set_yticklabels(tokens)\n        ax.set_title(f'Head {head_id}')\n\n    plt.tight_layout()\n    plt.show()\n\n","metadata":{"id":"guzGxfcV1Cba"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\n# Используйте правильное название предобученной модели для токенизатора\ntokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\ntext = \"раз два три четыре.\"\n# text = df['Задача'].sample(1).tolist() \n\nmodel = rubert_tiny_full_finetuned # rubert_tiny_finetuned_with_freezed_backbone \nattention_head_ids = [0, 3]  # Головы внимания, которые мы хотим визуализировать\n\ndraw_first_layer_attention_maps(attention_head_ids, text, model, tokenizer)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 7 (1 балл)\n\nПроведите инференс для всех моделей **ДО ДООБУЧЕНИЯ** на 2-3 текстах из датасета. Посмотрите на головы Attention первого слоя в каждой модели на выбранных текстах (отрисуйте их отдельно).\n\nПопробуйте их проинтерпретировать. Какие связи улавливают карты внимания? (если в модели много голов Attention, то проинтерпретируйте наиболее интересные)","metadata":{"id":"Iu0adKw4BLtF"}},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer\n\n# Загрузка токенизатора\ntokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n\n# Инициализация модели\nmodel_rubert_tiny = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\", output_attentions=True)\nmodel_rubert_tiny.eval()  # Перевести модель в режим оценки\n\n\ntexts = df['Задача'].sample(3).tolist()  # Случайный выбор трех текстов\n\nimport matplotlib.pyplot as plt\n\ndef visualize_attention(text, model, tokenizer):\n    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n    input_ids = inputs['input_ids']\n    attention_mask = inputs['attention_mask']\n\n    with torch.no_grad():\n        outputs = model(input_ids, attention_mask=attention_mask)\n        attentions = outputs.attentions  # Получаем внимания\n\n    # Визуализируем первый слой (первые две головы внимания)\n    attention = attentions[0][0, :2].detach().cpu().numpy()  # Первый слой, первые две головы\n    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n\n    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n    for i, ax in enumerate(axs):\n        ax.matshow(attention[i], cmap='viridis')\n        ax.set_xticks(range(len(tokens)))\n        ax.set_yticks(range(len(tokens)))\n        ax.set_xticklabels(tokens, rotation=90)\n        ax.set_yticklabels(tokens)\n        ax.set_title(f'Head {i+1} of Layer 1')\n\n    plt.show()\n\nfor text in texts:\n    visualize_attention(text, model_rubert_tiny, tokenizer)\n\n","metadata":{"id":"U2gEF3vkB6eR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Задание 8 (1 балл)\n\nСделайте то же самое для дообученных моделей. Изменились ли карты внимания и связи, которые они улавливают? Почему?","metadata":{"id":"pBNVrOpCCLqk"}},{"cell_type":"code","source":"### YOUR CODE IS HERE","metadata":{"id":"F5229WBICWEr"},"execution_count":null,"outputs":[]}]}