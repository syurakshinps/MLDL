{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<p style=\"align: center;\"><img src=\"https://static.tildacdn.com/tild6636-3531-4239-b465-376364646465/Deep_Learning_School.png\" width=\"400\"></p>\n\n# Домашнее задание. Обучение языковой модели с помощью LSTM (10 баллов)","metadata":{"id":"d0ADTojbpfLt"}},{"cell_type":"markdown","source":"Э\nВ этом задании Вам предстоит обучить языковую модель с помощью рекуррентной нейронной сети. В отличие от семинарского занятия, Вам необходимо будет работать с отдельными словами, а не буквами.\n\n\nУстановим модуль ```datasets```, чтобы нам проще было работать с данными.","metadata":{"id":"ldHSmYY6p_mZ"}},{"cell_type":"code","source":"!pip install datasets","metadata":{"id":"3yvNdv6cp_0P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Импорт необходимых библиотек","metadata":{"id":"rh9ZXSeCpng9"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tqdm.auto import tqdm\nfrom datasets import load_dataset\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom sklearn.model_selection import train_test_split\nimport nltk\n\nfrom collections import Counter\nfrom typing import List\n\nimport seaborn\nseaborn.set(palette='summer')","metadata":{"id":"XOJi16bLpd_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')","metadata":{"id":"91JuM0SQvXud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"id":"adJC8ShFq9HM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Подготовка данных\n\nВоспользуемся датасетом imdb. В нем хранятся отзывы о фильмах с сайта imdb. Загрузим данные с помощью функции ```load_dataset```","metadata":{"id":"pwsfS1ENq5ig"}},{"cell_type":"code","source":"# Загрузим датасет\ndataset = load_dataset('imdb')","metadata":{"id":"qHLNWOfJqSfc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Препроцессинг данных и создание словаря (1 балл)\n\nДалее вам необходмо самостоятельно произвести препроцессинг данных и получить словарь или же просто ```set``` строк. Что необходимо сделать:\n\n1. Разделить отдельные тренировочные примеры на отдельные предложения с помощью функции ```sent_tokenize``` из бибилиотеки ```nltk```. Каждое отдельное предложение будет одним тренировочным примером.\n2. Оставить только те предложения, в которых меньше ```word_threshold``` слов.\n3. Посчитать частоту вхождения каждого слова в оставшихся предложениях. Для деления предлоения на отдельные слова удобно использовать функцию ```word_tokenize```.\n4. Создать объект ```vocab``` класса ```set```, положить в него служебные токены '\\<unk\\>', '\\<bos\\>', '\\<eos\\>', '\\<pad\\>' и vocab_size самых частовстречающихся слов.   ","metadata":{"id":"24gn7CuZ9agP"}},{"cell_type":"code","source":"sentences = []\nword_threshold = 32\n\n# Получить отдельные предложения и поместить их в sentences","metadata":{"id":"Ins2tVCdsS47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Всего предложений:\", len(sentences))","metadata":{"id":"bxeBxP3J1Rj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Посчитаем для каждого слова его встречаемость.","metadata":{"id":"iT82XkT6ULA_"}},{"cell_type":"code","source":"words = Counter()\n\n# Расчет встречаемости слов","metadata":{"id":"nEvCN0Y1w1yH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Добавим в словарь ```vocab_size``` самых встречающихся слов.","metadata":{"id":"B4k4uSoHUSI0"}},{"cell_type":"code","source":"vocab = set()\nvocab_size = 40000\n\n# Наполнение словаря","metadata":{"id":"oUBNwsK9xLIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert '<unk>' in vocab\nassert '<bos>' in vocab\nassert '<eos>' in vocab\nassert '<pad>' in vocab\nassert len(vocab) == vocab_size + 4","metadata":{"id":"ieT0DFUpXnV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Всего слов в словаре:\", len(vocab))","metadata":{"id":"JhACW2CQyck5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Подготовка датасета (1 балл)\n\nДалее, как и в семинарском занятии, подготовим датасеты и даталоадеры.\n\nВ классе ```WordDataset``` вам необходимо реализовать метод ```__getitem__```, который будет возвращать сэмпл данных по входному idx, то есть список целых чисел (индексов слов).\n\nВнутри этого метода необходимо добавить служебные токены начала и конца последовательности, а также токенизировать соответствующее предложение с помощью ```word_tokenize``` и сопоставить ему индексы из ```word2ind```.","metadata":{"id":"UmeRYKSIUcdE"}},{"cell_type":"code","source":"word2ind = {char: i for i, char in enumerate(vocab)}\nind2word = {i: char for char, i in word2ind.items()}","metadata":{"id":"iD7SmSy3v2dl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WordDataset:\n    def __init__(self, sentences):\n        self.data = sentences\n        self.unk_id = word2ind['<unk>']\n        self.bos_id = word2ind['<bos>']\n        self.eos_id = word2ind['<eos>']\n        self.pad_id = word2ind['<pad>']\n\n    def __getitem__(self, idx: int) -> List[int]:\n        tokenized_sentence = []\n        # Допишите код здесь\n\n        return tokenized_sentence\n\n    def __len__(self) -> int:\n        return len(self.data)","metadata":{"id":"FVzXL17PzC7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn_with_padding(\n    input_batch: List[List[int]], pad_id=word2ind['<pad>']) -> torch.Tensor:\n    seq_lens = [len(x) for x in input_batch]\n    max_seq_len = max(seq_lens)\n\n    new_batch = []\n    for sequence in input_batch:\n        for _ in range(max_seq_len - len(sequence)):\n            sequence.append(pad_id)\n        new_batch.append(sequence)\n\n    sequences = torch.LongTensor(new_batch).to(device)\n\n    new_batch = {\n        'input_ids': sequences[:,:-1],\n        'target_ids': sequences[:,1:]\n    }\n\n    return new_batch","metadata":{"id":"I6CtYNMp2_g0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_sentences, eval_sentences = train_test_split(sentences, test_size=0.2)\neval_sentences, test_sentences = train_test_split(sentences, test_size=0.5)\n\ntrain_dataset = WordDataset(train_sentences)\neval_dataset = WordDataset(eval_sentences)\ntest_dataset = WordDataset(test_sentences)\n\nbatch_size = 128\n\ntrain_dataloader = DataLoader(\n    train_dataset, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n\neval_dataloader = DataLoader(\n    eval_dataset, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n\ntest_dataloader = DataLoader(\n    test_dataset, collate_fn=collate_fn_with_padding, batch_size=batch_size)","metadata":{"id":"6xmeK9Ys1BIG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Обучение и архитектура модели\n\nВам необходимо на практике проверить, что влияет на качество языковых моделей. В этом задании нужно провести серию экспериментов с различными вариантами языковых моделей и сравнить различия в конечной перплексии на тестовом множестве.\n\nВозмоэные идеи для экспериментов:\n\n* Различные RNN-блоки, например, LSTM или GRU. Также можно добавить сразу несколько RNN блоков друг над другом с помощью аргумента num_layers. Вам поможет официальная документация [здесь](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n* Различные размеры скрытого состояния. Различное количество линейных слоев после RNN-блока. Различные функции активации.\n* Добавление нормализаций в виде Dropout, BatchNorm или LayerNorm\n* Различные аргументы для оптимизации, например, подбор оптимального learning rate или тип алгоритма оптимизации SGD, Adam, RMSProp и другие\n* Любые другие идеи и подходы\n\nПосле проведения экспериментов необходимо составить таблицу результатов, в которой описан каждый эксперимент и посчитана перплексия на тестовом множестве.\n\nУчтите, что эксперименты, которые различаются, например, только размером скрытого состояния или количеством линейных слоев считаются, как один эксперимент.\n\nУспехов!","metadata":{"id":"SMAexY7Y45E4"}},{"cell_type":"markdown","source":"### Функция evaluate (1 балл)\n\nЗаполните функцию ```evaluate```","metadata":{"id":"KP1cO-3bmDv9"}},{"cell_type":"code","source":"def evaluate(model, criterion, dataloader) -> float:\n    model.eval()\n    perplexity = []\n    with torch.no_grad():\n        for batch in dataloader:\n            logits = # Посчитайте логиты предсказаний следующих слов\n            loss = criterion(logits, batch['target_ids'].flatten())\n            perplexity.append(torch.exp(loss).item())\n\n    perplexity = sum(perplexity) / len(perplexity)\n\n    return perplexity","metadata":{"id":"XUlMUVJ3mL4r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train loop (1 балл)\n\nНапишите функцию для обучения модели.","metadata":{"id":"bLV63Vsk7loy"}},{"cell_type":"code","source":"def train_model(...):\n    # Напишите код здесь","metadata":{"id":"bSZmUC3YmocP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Первый эксперимент (2 балла)\n\nОпределите архитектуру модели и обучите её.","metadata":{"id":"hXmeyhBQmuq4"}},{"cell_type":"code","source":"class LanguageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # Опишите свою нейронную сеть здесь\n\n    def forward(self, input_batch: torch.Tensor) -> torch.Tensor:\n        # А тут опишите forward pass модели\n\n        return","metadata":{"id":"qaWvqNJom0ij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Обучите модель здесь","metadata":{"id":"TxbEzn5fnBOY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Второй эксперимент (2 балла)\n\nПопробуйте что-то поменять в модели или в пайплайне обучения, идеи для экспериментов можно подсмотреть выше.","metadata":{"id":"X1EW4faIm0tl"}},{"cell_type":"code","source":"# Проведите второй эксперимент","metadata":{"id":"wkSE4jR1XzTg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Отчет (2 балла)\n\nОпишите проведенные эксперименты. Сравните перплексии полученных моделей. Предложите идеи по улучшению качества моделей.","metadata":{"id":"Y5V9H3eoFeAu"}},{"cell_type":"code","source":"","metadata":{"id":"M2GCDVeeF8LP"},"execution_count":null,"outputs":[]}]}